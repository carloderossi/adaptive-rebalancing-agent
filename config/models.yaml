ollama:
  host: "http://localhost:11434"   # default Ollama host

models:
  analyst: "qwen2.5-coder:14b"
  strategist: "deepseek-coder-v2:16b"
  explainer: "mistral:7b"
  orchestrator: "qwen2.5:7b"

defaults:
  temperature: 0.2
  max_tokens: 1024